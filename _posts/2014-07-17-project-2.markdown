---
layout: default
modal-id: 2
title: Image captioning and Text to image generator
date: 2021-06-20
img: clip_demo_1.jpg
alt: CLIP_handout
project-date: June 2021
category: NLP, zero shot classifier, image captioning, text to image 
short-description: A neural network is pretrained on variety of (image , text) pairs, which is then instructed with text supervision to accurately predict a text snippet describing the input image. (Exploring Research paper - Open AI CLIP)
description: Predict accurate text snippets describing the input image , Generate appropriate image when given a text snippet associated to that image.  
solution: The solution to this obective starts with a pretraining step which is also called as contrastive learnining step in which the model is trained on the Image representation (created by a transformer as an encoder) and Text representation (created by another encoder) from scratch, the objective of this training is to maximize the cosine similarity between the N real/correct pairs of image representation and the text representation and minimizing the N^2 - N incorrect set of pairs, optimized using a cross entropy. This training creates a multimodal embedded representation which is further used for zero shot classification.
results: As mentioned in the research paper it was found that the model matches the performance of ResNet50 on ImageNet dataset without using any of the labeled example in the dataset which overcomes many challenged in computer vision
github_url: https://github.com/prabhupad26/100daysofML/tree/main/DAY19-25%20CLIP/text_to_img_ui
---